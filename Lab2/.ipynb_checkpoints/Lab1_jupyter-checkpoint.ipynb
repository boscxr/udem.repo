{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratorio 2: Getting started with OpenCV for image and video processing\n",
    "\n",
    "Elaborado por: Oscar Omar Martínez Lujano \n",
    "Matrícula: 352228  \n",
    "Carrera: ITR  \n",
    "Fecha: 2019-02-12  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introducción\n",
    "\n",
    "OpenCV empezó en 1999 en Intel, por Gary Bradsky. OpenCV es una biblioteca libre de visión artificial. Desde que apareció su primera versión alfa en el mes de enero de 1999, se ha utilizado en infinidad de aplicaciones. Desde sistemas de seguridad con detección de movimiento, hasta aplicaciones de control de procesos donde se requiere reconocimiento de objetos. Esto se debe a que su publicación se da bajo licencia BSD, que permite que sea usada libremente para propósitos comerciales y de investigación con las condiciones en ella expresadas. OpenCV soporta muchos algoritmos relacionados con visión computacional, _machine learning_ y cada día crece mas y mas.\n",
    "\n",
    "Phyton is un lenguaje de programación que empezó por Guido van Rossum, el cuál se hizo muy popular en poco tiempo debido a su simplicidad y un código muy fácil de entender. Python facilita al programador para expresar sus ideas in menos líneas de código.\n",
    "\n",
    "A comparación de otros lenguajes como C/C++ , python es mas lento. Pero una ventaja de Python es que puede ser transformado fácilmente con  C/C++. Esta opcion nos ayuda a escribir códigos en C/C++ y crear un contenedor de Python, y así poder usar esos contenedores como módulos de Python. Esto nos da ventajas como es el que nuestro código es tan rápido como el original de C/C++, ya que el que está corriendo en el _background_ es C/C++. También es muy fácil trabajar en Python. Es así como trabaja OpenCV-Python, es un _wrapper_ Python alrededor de la implementación original C++. \n",
    "\n",
    "El hecho de que podamos usar Numpy, hace que las tareas sean todavía mucho más fáciles. Numpy está altamente optimizado para librerías de operaciones numéricas. Eso le da un estilo muy a la MATLAB. Todos los arreglos de OpenCV son convertidos a arreglos de Numpy. Asi que cualquier operación que hagas en Numpy puede ser combinada con OpenCV. esto incrementa el número de opciones por usar.\n",
    "\n",
    "Es por todo esto que OpenCV-Python es una herramienta muy apropiada para el rápido desarrollo de prototipo de problemas de computación visual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objetivos \n",
    "En este laboratorio nos enfocaremos en dos cosas:\n",
    "\n",
    "- Empezar a trabajar con imágenes: la lectura, visualización y almacenamiento de imágenes procesadas se encuentran entre los aspectos fundamentales del procesamiento de imágenes y la aplicación de visión por computadora. Se aprende a leer una imagen del disco, visualizarla y cómo escribirla de nuevo en el disco.\n",
    "\n",
    "- Empezar a trabajar con videos: como capturar y visualizar una secuencia de video en vivo adquirida desde una cámara web conectada a una Raspberry Pi, se aprende a leer un archivo de video del disco y procesar un poco de video andes de que se procese y se escriba en una archivo nuevo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedimiento\n",
    "En las siguientes celdas de código y texto, el estudiante mostrará el procedimiento realizado en la práctica, mostrando imágenes de salida, o enlace a videos capturados con la camara. \n",
    "\n",
    "La siguiente linea muestra un ejemplo para incluir enlaces externos:\n",
    "\n",
    "[Ver imagen de udem](https://www.google.com/search?q=udem&num=20&client=ubuntu&hs=lvY&channel=fs&source=lnms&tbm=isch&sa=X&ved=0ahUKEwjK6Nymn6HgAhVFL6wKHfsFAtsQ_AUIDigB&biw=1920&bih=959#imgrc=s2Qnk7dbzmnsxM:)\n",
    "\n",
    "Para incluir imágenes locales, lo podrá hacer de la siguiente manera:\n",
    "\n",
    "<img src=\"figs/vehicular-traffic.jpg\" width=\"800\" alt=\"Combined Image\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación de librerías\n",
    "Las siguientes celdas de código implementan la lectura, visualización y escritura de imagen en disco. Primero, se importan las librerías que serán utilizadas en el desarrollo de la práctica. La primera de ellas es la librería ```numpy``` utilizada para creación y manipulación de listas, análisis numérico, etc. La segunda librería es ```cv2```, ésta hace uso de la librería OpenCV, la cual implementa una gran variedad de algorítmos de procesamiento de imágenes y visión computaciónal. En nuestra práctica, ```cv2``` nos permitirá leer, procesar, visualizar y escribir imágenes en archivo....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa librerías estandar\n",
    "import numpy as np\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output image has been saved in /figs/vehicular-traffic-greyscale.png\n",
      "windows have been closed properly - bye!\n"
     ]
    }
   ],
   "source": [
    "# read in input image\n",
    "img_in = cv2.imread('figs/vehicular-traffic.jpg', cv2.IMREAD_COLOR) # alternatively, you can use cv2.IMREAD_GRAYSCALE\n",
    "\n",
    "# create a new window for image visualisation purposes\n",
    "cv2.namedWindow(\"input image\", cv2.WINDOW_AUTOSIZE)  # alternatively, you can use cv2.WINDOW_NORMAL\n",
    "\n",
    "# visualise input image\n",
    "cv2.imshow(\"input image\", img_in)\n",
    "\n",
    "# convert input image from colour to greyscale\n",
    "img_out = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# visualise greyscale image\n",
    "cv2.imshow(\"greyscale image\", img_out)\n",
    "\n",
    "# wait for the user to press a key\n",
    "key = cv2.waitKey(0)\n",
    "\n",
    "# if user presses 's', the grayscale image is write to an image file\n",
    "if key == ord(\"s\"):\n",
    "    \n",
    "    cv2.imwrite('figs/vehicular-traffic-greyscale.png', img_out)\n",
    "    print('output image has been saved in /figs/vehicular-traffic-greyscale.png')\n",
    "\n",
    "# destroy windows to free memory  \n",
    "cv2.destroyAllWindows()\n",
    "print('windows have been closed properly - bye!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: image  ../figs/vehicular-traffic.jpg could not be read\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.0) /io/opencv/modules/imgproc/src/color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f42e2de3ced3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# run first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-f42e2de3ced3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# call processing image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mprocessing_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_image_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_image_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f42e2de3ced3>\u001b[0m in \u001b[0;36mprocessing_image\u001b[0;34m(img_in_name, img_out_name)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# convert input image from colour to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mimg_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# create a new window for image purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.0.0) /io/opencv/modules/imgproc/src/color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "def options():\n",
    "    # parse command line arguments\n",
    "    parser = argparse.ArgumentParser('Read, visualise and write image into disk')\n",
    "    parser.add_argument('-i', '--in_image_name', help='input image name', required=True)\n",
    "    parser.add_argument('-o', '--out_image_name', help='output image name', required=True)\n",
    "    args = vars(parser.parse_args())\n",
    "    \n",
    "    return args\n",
    "\n",
    "def processing_image(img_in_name, img_out_name):\n",
    "    \n",
    "     # read in image from file\n",
    "    img_in = cv2.imread(img_in_name, cv2.IMREAD_COLOR) # alternatively, you can use cv2.IMREAD_GRAYSCALE\n",
    "\n",
    "    # verify that image exists\n",
    "    if img_in is None:\n",
    "        print('ERROR: image ', img_in_name, 'could not be read')\n",
    "        exit()\n",
    "\n",
    "    # convert input image from colour to grayscale\n",
    "    img_out = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # create a new window for image purposes\n",
    "    cv2.namedWindow(\"input image\", cv2.WINDOW_AUTOSIZE)  # alternatively, you can use cv2.WINDOW_NORMAL\n",
    "    cv2.namedWindow(\"output image\", cv2.WINDOW_AUTOSIZE) # that option will allow you for window resizing\n",
    "\n",
    "    # visualise input and output image\n",
    "    cv2.imshow(\"input image\", img_in)\n",
    "    cv2.imshow(\"output image\", img_out)\n",
    "\n",
    "    # wait for the user to press a key\n",
    "    key = cv2.waitKey(0)\n",
    "\n",
    "    # if user pressed 's', the grayscale image is write to disk\n",
    "    if key == ord(\"s\"):\n",
    "        cv2.imwrite(img_out_name, img_out)\n",
    "        print('output image has been saved in ../figs/vehicular-traffic-greyscale.png')\n",
    "\n",
    "    # destroy windows to free memory  \n",
    "    cv2.destroyAllWindows()\n",
    "    print('windows have been closed properly')\n",
    "\n",
    "    \n",
    "# main function\n",
    "def main():    \n",
    "    \n",
    "    # uncomment these lines when running on jupyter notebook\n",
    "    # and comment when running as a script on linux terminal\n",
    "    args = {\n",
    "            \"in_image_name\": \"figs/vehicular-traffic.jpg\",\n",
    "            \"out_image_name\": \"figs/vehicular-traffic-greyscale.png\"\n",
    "            }\n",
    "    \n",
    "    # comment the following line when running on jupyter notebook\n",
    "    # and uncomment when running as a script on linux terminarl\n",
    "    #args = options()\n",
    "    \n",
    "    in_image_name = args['in_image_name']\n",
    "    out_image_name = args['out_image_name']\n",
    "    \n",
    "    # call processing image\n",
    "    processing_image(in_image_name, out_image_name)\n",
    "    \n",
    "    \n",
    "# run first\n",
    "if __name__=='__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture video from camera - Basic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "# create a VideoCapture object\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# main loop\n",
    "while(True):\n",
    "\n",
    "    # capture new frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # convert from colour to grayscale image\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # visualise image\n",
    "    cv.imshow('frame', frame)\n",
    "\n",
    "    # wait for the user to press 'q' to close the window\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release VideoCapture object\n",
    "cap.release()\n",
    "\n",
    "# destroy windows to free memory\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture video from camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def configure_videoCapture(device_index):\n",
    "\n",
    "    \"\"\"\n",
    "    Configure video capture object to handle video device.\n",
    "\n",
    "    Parameters\n",
    "        device_index: int value indicating the index number to access camera\n",
    "\n",
    "    Returns\n",
    "        cap: videoCapture-type object\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # create a videoCapture object and returns either a True or False\n",
    "    cap = cv2.VideoCapture(device_index)\n",
    "\n",
    "    # if camera could not be opened, it displays an error and exits\n",
    "    if not cap.isOpened():\n",
    "        print(\"ERROR: Camera could not be opened\")\n",
    "        exit()\n",
    "\n",
    "    # return videoCapture object 'cap'\n",
    "    return cap\n",
    "\n",
    "\n",
    "def print_video_frame_specs(cap):\n",
    "\n",
    "    \"\"\"\n",
    "    Print video specifications such as video frame width and height, fps,\n",
    "    brightness, contrast, saturation, gain, and exposure.\n",
    "\n",
    "    Parameters\n",
    "        cap: video capture object\n",
    "\n",
    "    Returns\n",
    "        None: this definition only prints information on the command line\n",
    "              window.\n",
    "    \"\"\"    \n",
    "\n",
    "    # retrieve video properties\n",
    "    ret, frame = cap.read()\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # verify that frame was properly captured\n",
    "    if ret == False:\n",
    "        print(\"ERROR: current frame could not be read\")\n",
    "        exit()\n",
    "\n",
    "    else: # if so, video frame stats are displayed\n",
    "\n",
    "        # print video frames specifications\n",
    "        print('\\nVideo specifications:')\n",
    "        print('\\tframe width: ', cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        print('\\tframe height: ', cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        print('\\tframe rate: ', cap.get(cv2.CAP_PROP_FPS))\n",
    "        print('\\tbrightness: ', cap.get(cv2.CAP_PROP_BRIGHTNESS))\n",
    "        print('\\tcontrast: ', cap.get(cv2.CAP_PROP_CONTRAST))\n",
    "        print('\\tsaturation: ', cap.get(cv2.CAP_PROP_SATURATION))\n",
    "        print('\\thue: ', cap.get(cv2.CAP_PROP_GAIN))\n",
    "        print('\\texposure: ', cap.get(cv2.CAP_PROP_EXPOSURE))\n",
    "\n",
    "    # return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def capture_and_process_video(cap):\n",
    "\n",
    "    \"\"\"\n",
    "    Capture live video from a camera connected to your computer. Each frame is\n",
    "    flipped and visualised together with the original frame on separate windows.\n",
    "\n",
    "    Parameters\n",
    "        cap: video capture object\n",
    "\n",
    "    Returns\n",
    "        None: none\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # create a new window for image purposes\n",
    "    cv2.namedWindow(\"input image\", cv2.WINDOW_AUTOSIZE)  # alternatively, you can use cv2.WINDOW_NORMAL\n",
    "    cv2.namedWindow(\"output image\", cv2.WINDOW_AUTOSIZE) # that option will allow you for window resizing\n",
    "\n",
    "\n",
    "    # main loop\n",
    "    print('\\ncapturing video ...')\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "        # capture frame by frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "\t    # verify that frame was properly captured\n",
    "        if ret == False:\n",
    "            print(\"ERROR: current frame could not be read\")\n",
    "            break\n",
    "\n",
    "        # if frame was properly captured, it is converted\n",
    "        # from a colour to a grayscale image\n",
    "        frame_out = cv2.flip(frame,0)\n",
    "\n",
    "        # visualise current frame and grayscale frame\n",
    "        cv2.imshow(\"input image\", frame)\n",
    "        cv2.imshow(\"output image\", frame_out)\n",
    "\n",
    "\n",
    "        # wait for the user to press a key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # return none\n",
    "    return None\n",
    "\n",
    "\n",
    "def free_memory(cap):\n",
    "\n",
    "    \"\"\"\n",
    "    Free memory by releasing videoCapture 'cap' and by destroying/closing all\n",
    "    open windows.\n",
    "\n",
    "    Parameters\n",
    "        cap: video capture object\n",
    "\n",
    "    Returns\n",
    "        None: none\n",
    "    \"\"\"\n",
    "\n",
    "    # when finished, release the VideoCapture object and close windows to free memory\n",
    "    print('closing camera ...')\n",
    "    cap.release()\n",
    "    print('camera closed')\n",
    "    cv2.destroyAllWindows()\n",
    "    print('program finished - bye!\\n')\n",
    "\n",
    "    # return none\n",
    "    return None\n",
    "\n",
    "\n",
    "def run_pipeline(device_index=0):\n",
    "    \"\"\"\n",
    "    Run pipeline to capture, process and visualise both the original frame and\n",
    "    processed frame.\n",
    "\n",
    "    Parameters\n",
    "        device_index: device index - 0 default\n",
    "\n",
    "    Returns\n",
    "        arg: None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # pipeline\n",
    "    cap = configure_videoCapture(device_index)\n",
    "    print_video_frame_specs(cap)\n",
    "    capture_and_process_video(cap)\n",
    "    free_memory(cap)\n",
    "\n",
    "    # return none\n",
    "    return None\n",
    "\n",
    "\n",
    "# run pipeline    \n",
    "run_pipeline(device_index = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Play video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# create a VideoCapture object and specify video file to be read\n",
    "cap = cv2.VideoCapture('../datasets/videos/highway_right_solid_white_line_short.mp4')\n",
    "\n",
    "# main loop\n",
    "while(cap.isOpened()):\n",
    "\n",
    "    # read current frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # validate that frame was capture correctly\n",
    "    if ret:\n",
    "        \n",
    "        # convert frame from colour to gray scale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # show current frame\n",
    "        cv2.imshow('frame',gray)\n",
    "\n",
    "    # wait for the user to press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release VideoCapture object\n",
    "cap.release()\n",
    "\n",
    "# destroy windows to free memory\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones\n",
    "En esta sección, el estudiante incluirá sus conclusiones ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
