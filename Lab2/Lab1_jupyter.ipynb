{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratorio 2: Getting started with OpenCV for image and video processing\n",
    "\n",
    "Elaborado por: Oscar Omar Martínez Lujano \n",
    "Matrícula: 352228  \n",
    "Carrera: ITR  \n",
    "Fecha: 2019-02-12  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introducción\n",
    "\n",
    "OpenCV empezó en 1999 en Intel, por Gary Bradsky. OpenCV es una biblioteca libre de visión artificial. Desde que apareció su primera versión alfa en el mes de enero de 1999, se ha utilizado en infinidad de aplicaciones. Desde sistemas de seguridad con detección de movimiento, hasta aplicaciones de control de procesos donde se requiere reconocimiento de objetos. Esto se debe a que su publicación se da bajo licencia BSD, que permite que sea usada libremente para propósitos comerciales y de investigación con las condiciones en ella expresadas. OpenCV soporta muchos algoritmos relacionados con visión computacional, _machine learning_ y cada día crece mas y mas.\n",
    "\n",
    "Phyton is un lenguaje de programación que empezó por Guido van Rossum, el cuál se hizo muy popular en poco tiempo debido a su simplicidad y un código muy fácil de entender. Python facilita al programador para expresar sus ideas in menos líneas de código.\n",
    "\n",
    "A comparación de otros lenguajes como C/C++ , python es mas lento. Pero una ventaja de Python es que puede ser transformado fácilmente con  C/C++. Esta opcion nos ayuda a escribir códigos en C/C++ y crear un contenedor de Python, y así poder usar esos contenedores como módulos de Python. Esto nos da ventajas como es el que nuestro código es tan rápido como el original de C/C++, ya que el que está corriendo en el _background_ es C/C++. También es muy fácil trabajar en Python. Es así como trabaja OpenCV-Python, es un _wrapper_ Python alrededor de la implementación original C++. \n",
    "\n",
    "El hecho de que podamos usar Numpy, hace que las tareas sean todavía mucho más fáciles. Numpy está altamente optimizado para librerías de operaciones numéricas. Eso le da un estilo muy a la MATLAB. Todos los arreglos de OpenCV son convertidos a arreglos de Numpy. Asi que cualquier operación que hagas en Numpy puede ser combinada con OpenCV. esto incrementa el número de opciones por usar.\n",
    "\n",
    "Es por todo esto que OpenCV-Python es una herramienta muy apropiada para el rápido desarrollo de prototipo de problemas de computación visual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objetivos \n",
    "En este laboratorio nos enfocaremos en dos cosas:\n",
    "\n",
    "- Empezar a trabajar con imágenes: la lectura, visualización y almacenamiento de imágenes procesadas se encuentran entre los aspectos fundamentales del procesamiento de imágenes y la aplicación de visión por computadora. Se aprende a leer una imagen del disco, visualizarla y cómo escribirla de nuevo en el disco.\n",
    "\n",
    "- Empezar a trabajar con videos: como capturar y visualizar una secuencia de video en vivo adquirida desde una cámara web conectada a una Raspberry Pi, se aprende a leer un archivo de video del disco y procesar un poco de video andes de que se procese y se escriba en una archivo nuevo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedimiento\n",
    "La siguiente imagen es la que se utiliza para hacer el procesamiento de imágenes:\n",
    "\n",
    "<img src=\"figs/vehicular-traffic.jpg\" width=\"400\" alt=\"Combined Image\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Importación de librerías\n",
    "\n",
    "Las siguientes librerías son utilizadas a lo largo de todos los códigos de esta práctica\n",
    "\n",
    "\n",
    "- ```cv2```: Implementa una gran variedad de algorítmos de procesamiento de imágenes y visión computacional.\n",
    "- ```numpy:``` Crea y manipula listas, análisis numérico, etc.\n",
    "- ```argparse:``` Usada para analizar argumentos que pasan por la consola, analiza manualmente los argumentos escritos en un diccionario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa librerías estandar\n",
    "import numpy as np\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Reading, visualising and saving images\n",
    "\n",
    "- `cv2.imread(filename[, flags])`\n",
    "    - Carga una imagen de un archivo\n",
    "    - filename - nombre del archivo que será cargado.\n",
    "    - flags - CV_LOAD_IMAGE_ANYDEPTH | CV_LOAD_IMAGE_COLOR | CV_LOAD_IMAGE_GRAYSCALE\n",
    "    - **returns** – Mat object.\n",
    "- `cv2.namedWindow(winname[, flags])`\n",
    "    - Crea una ventana\n",
    "    - name - Nombre de la ventana que será usada para identificarla\n",
    "    - flags - WINDOW_NORMAL | WINDOW_AUTOSIZE | WINDOW_OPENGL\n",
    "    - **returns** – None\n",
    "- `cv2.imshow(winname, mat)`\n",
    "    - Despliega una imagen en la ventana especificada\n",
    "    - winname - nombre de la ventana\n",
    "    - image - imagen que será mostrada\n",
    "    - **returns** – None\n",
    "- `cv2.waitKey([delay])`\n",
    "    - Espera a que presionen una tecla\n",
    "    - delay - Delay en milisegundos, 0 es el valor especial que significa “forever”.\n",
    "    - **returns** – el código de la tecla oprimida o -1 si no se presionó nada\n",
    "- `cv2.imwrite(filename, img[, params])`\n",
    "    - Guarda una imagen en el archivo especificado\n",
    "    - filename - nombre del archivo\n",
    "    - image - imagen que se guardará\n",
    "    - params - Formato específico de los parametros guardados codificados como pares. Check docs.\n",
    "    - **returns** – retval\n",
    "- `cv2.destroyAllWindows()`\n",
    "    - Destrute todas las ventanas HighGUI\n",
    "    - **returns** – None\n",
    "\n",
    "Información obtenida de:\n",
    "- https://docs.opencv.org/3.0-beta/modules/imgcodecs/doc/reading_and_writing_images.html?highlight=imwrite#cv2.imwrite\n",
    "- https://docs.opencv.org/3.0-beta/modules/highgui/doc/user_interface.html?highlight=waitkey#waitkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows have been closed properly - bye!\n"
     ]
    }
   ],
   "source": [
    "# read in input image\n",
    "img_in = cv2.imread('figs/vehicular-traffic.jpg', cv2.IMREAD_COLOR) # alternatively, you can use cv2.IMREAD_GRAYSCALE\n",
    "\n",
    "# create a new window for image visualisation purposes\n",
    "cv2.namedWindow(\"input image\", cv2.WINDOW_AUTOSIZE)  # alternatively, you can use cv2.WINDOW_NORMAL\n",
    "\n",
    "# visualise input image\n",
    "cv2.imshow(\"input image\", img_in)\n",
    "\n",
    "# convert input image from colour to greyscale\n",
    "img_out = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# visualise greyscale image\n",
    "cv2.imshow(\"greyscale image\", img_out)\n",
    "\n",
    "# wait for the user to press a key\n",
    "key = cv2.waitKey(0)\n",
    "\n",
    "# if user presses 's', the grayscale image is write to an image file\n",
    "if key == ord(\"s\"):\n",
    "    \n",
    "    cv2.imwrite('figs/vehicular-traffic-greyscale.png', img_out)\n",
    "    print('output image has been saved in /figs/vehicular-traffic-greyscale.png')\n",
    "\n",
    "# destroy windows to free memory  \n",
    "cv2.destroyAllWindows()\n",
    "print('windows have been closed properly - bye!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. A more elaborated program to read, visualise, and save an image\n",
    "\n",
    "- `parser.add_argument(name or flags...[, action][, nargs][, const][, default][, type][, choices][, required][, help][, metavar][, dest])`\n",
    "    - Define como una linea de comando singular debería de ser analizada.\n",
    "    - name or flags - Either a name or a list of option strings, e.g. foo or -f, --foo.\n",
    "    - action - acción de tipo básica que será tomada cuando este argumento sea encontrado en la linea de comando.\n",
    "    - nargs - el numero de argumentos de linea de comando que deberían ser consumidos. \n",
    "    - const - valor constante requerido por una acción y selección nargs.\n",
    "    - default - el valor producido si el argumento está ausente en la linea de comando.\n",
    "    - type - el tipo al que el argumento de la linea de comando va a ser convertido\n",
    "    - choices - un contenedor con los valores permitidos para el argumento\n",
    "    - required - la linea de comando puede ser omitida (opcional)\n",
    "    - help - pequeña descripción de lo que el argumento hace\n",
    "    - metavar - nombre para el argumento en mensajes usados.\n",
    "    - dest - el nombre del atributo que se añade al obejto devuelto por parse_args()\n",
    "    - **returns** – None\n",
    "\n",
    "- `cv2.cvtColor(src, code[, dst[, dstCn]])`\n",
    "    - Convierte una imagen de un espacio de color a otro.\n",
    "    - src - imagen de entrada\n",
    "    - dst - imagen de salida del mismo tamaño y profundidad que src\n",
    "    - code - código de conversión de espacio de color. COLOR_BGR2GRAY, COLOR_BGR2XYZ, COLOR_BGR2YCrCb, COLOR_BGR2HSV, COLOR_BGR2HLS, COLOR_BGR2Lab, COLOR_BGR2Luv, COLOR_BayerBG2BGR\n",
    "    - dstCn – número de canales en la imagen destino.\n",
    "    - **returns** – Destination image\n",
    "    \n",
    "- `argparse.ArgumentParser(prog=None, usage=None, description=None, epilog=None, parents=[], formatter_class=argparse.HelpFormatter, prefix_chars='-', fromfile_prefix_chars=None, argument_default=None, conflict_handler='error', add_help=True)`\n",
    "    - Crea un nuevo objeto ArgumentParser.\n",
    "    - prog - el nombre del programa (default: sys.argv[0])\n",
    "    - usage - el string describiendo tel uso del programa (default: generated from arguments added to parser)\n",
    "    - description - texto para desplegar antes del help (default: none)\n",
    "    - epilog - texto para desplegar despues del help (default: none)\n",
    "    - parents - una lista de objetos ArgumentParser que deberían ser incluidos\n",
    "    - formatter_class - una clase para perosnalizar la salida help\n",
    "    - prefix_chars - lista de caracteres que anteponen argumentos opcionales (default: ‘-‘)\n",
    "    - fromfile_prefix_chars - lista de caracteres que anteponen archivos de argumentos adicionales que son leídos (default: None)\n",
    "    - argument_default - el valor default global para argumentos (default: None)\n",
    "    - conflict_handler - la estrategia de resolver opcionales conflictivos (usualmente innecesario)\n",
    "    - add_help - agrega un -h+\n",
    "    help option to the parser (default: True)\n",
    "    - **returns** – an ArgumentParser Object\n",
    "\n",
    "- `vars([object])`\n",
    "    - Regresa el \\_\\_dict__ attribute del objeto dado si el objeto tiene \\_\\_dict__ attribute.\n",
    "    - object - puede ser modulo, clase, instancia, o cualquier objeto que tenga \\_\\_dict__ attribute.\n",
    "    - **returns** – dict Object.\n",
    "\n",
    "\n",
    "Información obtenida de:\n",
    "- https://docs.opencv.org/3.0-beta/modules/imgproc/doc/miscellaneous_transformations.html#void%20cvtColor(InputArray%20src,%20OutputArray%20dst,%20int%20code,%20int%20dstCn)\n",
    "- https://docs.python.org/2/library/argparse.html#argparse.ArgumentParser.add_argument\n",
    "- https://www.programiz.com/python-programming/methods/built-in/vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows have been closed properly\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "def options():\n",
    "    # parse command line arguments\n",
    "    parser = argparse.ArgumentParser('Read, visualise and write image into disk')\n",
    "    parser.add_argument('-i', '--in_image_name', help='input image name', required=True)\n",
    "    parser.add_argument('-o', '--out_image_name', help='output image name', required=True)\n",
    "    args = vars(parser.parse_args())\n",
    "    \n",
    "    return args\n",
    "\n",
    "def processing_image(img_in_name, img_out_name):\n",
    "    \n",
    "     # read in image from file\n",
    "    img_in = cv2.imread(img_in_name, cv2.IMREAD_COLOR) # alternatively, you can use cv2.IMREAD_GRAYSCALE\n",
    "\n",
    "    # verify that image exists\n",
    "    if img_in is None:\n",
    "        print('ERROR: image ', img_in_name, 'could not be read')\n",
    "        exit()\n",
    "\n",
    "    # convert input image from colour to grayscale\n",
    "    img_out = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # create a new window for image purposes\n",
    "    cv2.namedWindow(\"input image\", cv2.WINDOW_AUTOSIZE)  # alternatively, you can use cv2.WINDOW_NORMAL\n",
    "    cv2.namedWindow(\"output image\", cv2.WINDOW_AUTOSIZE) # that option will allow you for window resizing\n",
    "\n",
    "    # visualise input and output image\n",
    "    cv2.imshow(\"input image\", img_in)\n",
    "    cv2.imshow(\"output image\", img_out)\n",
    "\n",
    "    # wait for the user to press a key\n",
    "    key = cv2.waitKey(0)\n",
    "\n",
    "    # if user pressed 's', the grayscale image is write to disk\n",
    "    if key == ord(\"s\"):\n",
    "        cv2.imwrite(img_out_name, img_out)\n",
    "        print('output image has been saved in ../figs/vehicular-traffic-greyscale.png')\n",
    "\n",
    "    # destroy windows to free memory  \n",
    "    cv2.destroyAllWindows()\n",
    "    print('windows have been closed properly')\n",
    "\n",
    "    \n",
    "# main function\n",
    "def main():    \n",
    "    \n",
    "    # uncomment these lines when running on jupyter notebook\n",
    "    # and comment when running as a script on linux terminal\n",
    "    args = {\n",
    "            \"in_image_name\": \"figs/vehicular-traffic.jpg\",\n",
    "            \"out_image_name\": \"figs/vehicular-traffic-greyscale.png\"\n",
    "            }\n",
    "    \n",
    "    # comment the following line when running on jupyter notebook\n",
    "    # and uncomment when running as a script on linux terminarl\n",
    "    #args = options()\n",
    "    \n",
    "    in_image_name = args['in_image_name']\n",
    "    out_image_name = args['out_image_name']\n",
    "    \n",
    "    # call processing image\n",
    "    processing_image(in_image_name, out_image_name)\n",
    "    \n",
    "    \n",
    "# run first\n",
    "if __name__=='__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Basic program to capture live video from camera\n",
    "- `cv2.VideoCapture([filename, device])`\n",
    "    - Construtora VideoCapture\n",
    "    - filename - nombre del archivo video abierto\n",
    "    - devide - id del dispositivo de captura del video abierto\n",
    "    - **returns** – <VideoCapture \\object> \n",
    "- `cv2.VideoCapture.read()`\n",
    "    - Graba, decodifica y returna el siguiente frame de video\n",
    "    - **returns** – retval, image \n",
    "- `cv2.VideoCapture.release()`\n",
    "    - Cierra el archivo de video o el dispositivo de captura.\n",
    "    - **returns** – None\n",
    "    \n",
    "Información obtenida de:\n",
    "- https://docs.opencv.org/3.0-beta/modules/videoio/doc/reading_and_writing_video.html?highlight=videocapture#videocapture-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "# create a VideoCapture object\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# main loop\n",
    "while(True):\n",
    "\n",
    "    # capture new frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # convert from colour to grayscale image\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # visualise image\n",
    "    cv.imshow('frame', frame)\n",
    "\n",
    "    # wait for the user to press 'q' to close the window\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release VideoCapture object\n",
    "cap.release()\n",
    "\n",
    "# destroy windows to free memory\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Basic program to capture live video from Raspberry Pi camera\n",
    "\n",
    "    Por el momento no se cuenta con cámara Raspberry Pi \n",
    "\n",
    "- `PiCamera(camera_num=0, stereo_mode='none', stereo_decimate=False, resolution=None, framerate=None, sensor_mode=0, led_pin=None, clock_mode='reset', framerate_range=None)`\n",
    "    - Da una interface de Python pura para la cámara Raspberry Pi\n",
    "    - **returns** - PiCamera object\n",
    "- `PiCamera.resolution`\n",
    "    - Recupera la resolución en la que la imagen, video y previews serán capturados\n",
    "- `PiCamera.framerate`\n",
    "    - Recupera el framerate en el que el video portable, imagenes, grabaciones de video correrán `PiRGBArray(camera, size=None)`\n",
    "    - Produce a 3D RGB arreglo de una captura RGB\n",
    "    - camera - objeto PiCamera\n",
    "    - **returns** – arreglo\n",
    "- `time.sleep(t)`\n",
    "    - Suspende la ejecución por el número dado de segundos\n",
    "    - t - este es el número de segundos que la ejecución será suspendida\n",
    "    - **returns** – None\n",
    "- `np.float32(c)`\n",
    "    - Crea un preciso float singular\n",
    "    - c – numero a convertir\n",
    "    - **returns** – single precision float.\n",
    "- `cv2.Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]])`\n",
    "    - image - entrada de imagen de 8-bit\n",
    "    - edges - salida del borde del mapa, single channels 8-bit image, tiene el mismo tamaño que la imagen\n",
    "    - threshold1 - primer threshold para el procedimiento de histéresis.\n",
    "    - threshold2 - segundo threshold oara el procedimiento de histéresis.\n",
    "    - apertureSize - tamaño de apertura para el operador Sobel()\n",
    "    - L2gradient - un flag, indicando cualquier norm L2 mas preciso\n",
    "    - **returns** - edges  \n",
    "- `ord(c)`\n",
    "    - Regresa un intero representando el punto código Unicode para el caracter Unicode dado\n",
    "    - c – string de longitud 1 el cual su punto código character string of length 1 whose Unicode code point is to be found.\n",
    "    - **returns** – int\n",
    "\n",
    "Información obtenida de:\n",
    "- https://picamera.readthedocs.io/en/release-1.10/api_array.html#pirgbarray\n",
    "- https://www.tutorialspoint.com/python/time_sleep.htm\n",
    "- https://docs.scipy.org/doc/numpy-1.13.0/user/basics.types.html\n",
    "- https://www.programiz.com/python-programming/methods/built-in/ord\n",
    "- https://docs.opencv.org/3.0-beta/modules/imgproc/doc/feature_detection.html?highlight=cv2.canny#cv2.Canny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f. A more elaborated program to capture, process and visualise video\n",
    "\n",
    "- `cv2.videoCapture.isOpened()`\n",
    "    - Retorna verdadero si el video capturado ya ha sido inicializado.\n",
    "    - **returns** - retval\n",
    "- `cv2.videoCapture.get(propId)`\n",
    "    - Retorna la propiedad VideoCapture especificada\n",
    "    - propId - Identificador propiedad\n",
    "    - **returns** - retval\n",
    "- `cv2.flip(src, flipCode[, dst])`\n",
    "    - Voltea un arreglo 2D verticalmente, horizontalmente o ambos ejes \n",
    "    - src - entrada de arreglo.\n",
    "    - dst - salida de arreglo del mismo tamaño del src\n",
    "    - flipCode - flag que especifica como voltear un arreglo, 0 significa voltear en el eje x, 1 significa eje y. Valores negativos significa voltear en ambos ejes.\n",
    "    - **returns** - dst\n",
    "    \n",
    "Información obtenida de:\n",
    "\n",
    "- https://docs.opencv.org/3.0-beta/modules/videoio/doc/reading_and_writing_video.html?highlight=cv2.videocapture.isopened#videocapture\n",
    "- https://docs.opencv.org/3.0-beta/modules/core/doc/operations_on_arrays.html?highlight=flip#cv2.flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Video specifications:\n",
      "\tframe width:  640.0\n",
      "\tframe height:  480.0\n",
      "\tframe rate:  30.0\n",
      "\tbrightness:  0.0\n",
      "\tcontrast:  50.0\n",
      "\tsaturation:  64.0\n",
      "\thue:  -1.0\n",
      "\texposure:  166.0\n",
      "\n",
      "capturing video ...\n",
      "closing camera ...\n",
      "camera closed\n",
      "program finished - bye!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def configure_videoCapture(device_index):\n",
    "\n",
    "    \"\"\"\n",
    "    Configure video capture object to handle video device.\n",
    "\n",
    "    Parameters\n",
    "        device_index: int value indicating the index number to access camera\n",
    "\n",
    "    Returns\n",
    "        cap: videoCapture-type object\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # create a videoCapture object and returns either a True or False\n",
    "    cap = cv2.VideoCapture(device_index)\n",
    "\n",
    "    # if camera could not be opened, it displays an error and exits\n",
    "    if not cap.isOpened():\n",
    "        print(\"ERROR: Camera could not be opened\")\n",
    "        exit()\n",
    "\n",
    "    # return videoCapture object 'cap'\n",
    "    return cap\n",
    "\n",
    "\n",
    "def print_video_frame_specs(cap):\n",
    "\n",
    "    \"\"\"\n",
    "    Print video specifications such as video frame width and height, fps,\n",
    "    brightness, contrast, saturation, gain, and exposure.\n",
    "\n",
    "    Parameters\n",
    "        cap: video capture object\n",
    "\n",
    "    Returns\n",
    "        None: this definition only prints information on the command line\n",
    "              window.\n",
    "    \"\"\"    \n",
    "\n",
    "    # retrieve video properties\n",
    "    ret, frame = cap.read()\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # verify that frame was properly captured\n",
    "    if ret == False:\n",
    "        print(\"ERROR: current frame could not be read\")\n",
    "        exit()\n",
    "\n",
    "    else: # if so, video frame stats are displayed\n",
    "\n",
    "        # print video frames specifications\n",
    "        print('\\nVideo specifications:')\n",
    "        print('\\tframe width: ', cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        print('\\tframe height: ', cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        print('\\tframe rate: ', cap.get(cv2.CAP_PROP_FPS))\n",
    "        print('\\tbrightness: ', cap.get(cv2.CAP_PROP_BRIGHTNESS))\n",
    "        print('\\tcontrast: ', cap.get(cv2.CAP_PROP_CONTRAST))\n",
    "        print('\\tsaturation: ', cap.get(cv2.CAP_PROP_SATURATION))\n",
    "        print('\\thue: ', cap.get(cv2.CAP_PROP_GAIN))\n",
    "        print('\\texposure: ', cap.get(cv2.CAP_PROP_EXPOSURE))\n",
    "\n",
    "    # return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def capture_and_process_video(cap):\n",
    "\n",
    "    \"\"\"\n",
    "    Capture live video from a camera connected to your computer. Each frame is\n",
    "    flipped and visualised together with the original frame on separate windows.\n",
    "\n",
    "    Parameters\n",
    "        cap: video capture object\n",
    "\n",
    "    Returns\n",
    "        None: none\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # create a new window for image purposes\n",
    "    cv2.namedWindow(\"input image\", cv2.WINDOW_AUTOSIZE)  # alternatively, you can use cv2.WINDOW_NORMAL\n",
    "    cv2.namedWindow(\"output image\", cv2.WINDOW_AUTOSIZE) # that option will allow you for window resizing\n",
    "\n",
    "\n",
    "    # main loop\n",
    "    print('\\ncapturing video ...')\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "        # capture frame by frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "\t    # verify that frame was properly captured\n",
    "        if ret == False:\n",
    "            print(\"ERROR: current frame could not be read\")\n",
    "            break\n",
    "\n",
    "        # if frame was properly captured, it is converted\n",
    "        # from a colour to a grayscale image\n",
    "        frame_out = cv2.flip(frame,0)\n",
    "\n",
    "        # visualise current frame and grayscale frame\n",
    "        cv2.imshow(\"input image\", frame)\n",
    "        cv2.imshow(\"output image\", frame_out)\n",
    "\n",
    "\n",
    "        # wait for the user to press a key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # return none\n",
    "    return None\n",
    "\n",
    "\n",
    "def free_memory(cap):\n",
    "\n",
    "    \"\"\"\n",
    "    Free memory by releasing videoCapture 'cap' and by destroying/closing all\n",
    "    open windows.\n",
    "\n",
    "    Parameters\n",
    "        cap: video capture object\n",
    "\n",
    "    Returns\n",
    "        None: none\n",
    "    \"\"\"\n",
    "\n",
    "    # when finished, release the VideoCapture object and close windows to free memory\n",
    "    print('closing camera ...')\n",
    "    cap.release()\n",
    "    print('camera closed')\n",
    "    cv2.destroyAllWindows()\n",
    "    print('program finished - bye!\\n')\n",
    "\n",
    "    # return none\n",
    "    return None\n",
    "\n",
    "\n",
    "def run_pipeline(device_index=0):\n",
    "    \"\"\"\n",
    "    Run pipeline to capture, process and visualise both the original frame and\n",
    "    processed frame.\n",
    "\n",
    "    Parameters\n",
    "        device_index: device index - 0 default\n",
    "\n",
    "    Returns\n",
    "        arg: None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # pipeline\n",
    "    cap = configure_videoCapture(device_index)\n",
    "    print_video_frame_specs(cap)\n",
    "    capture_and_process_video(cap)\n",
    "    free_memory(cap)\n",
    "\n",
    "    # return none\n",
    "    return None\n",
    "\n",
    "\n",
    "# run pipeline    \n",
    "run_pipeline(device_index = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g. Basic program to play a video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# create a VideoCapture object and specify video file to be read\n",
    "cap = cv2.VideoCapture('figs/highway_right_solid_white_line_short.mp4')\n",
    "\n",
    "# main loop\n",
    "while(cap.isOpened()):\n",
    "\n",
    "    # read current frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # validate that frame was capture correctly\n",
    "    if ret:\n",
    "        \n",
    "        # convert frame from colour to gray scale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # show current frame\n",
    "        cv2.imshow('frame',gray)\n",
    "\n",
    "    # wait for the user to press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release VideoCapture object\n",
    "cap.release()\n",
    "\n",
    "# destroy windows to free memory\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones\n",
    "En este laboratorio, usamos librerias de openCV y numpy. Aprendí lo básico para hacer uso de imágenes y video que se encuentran en el disco, así como el guardar imagenes nuevas. Entendí lo que hace cada función de cada código que se vió en este laboratorio y creo yo que lo mas importante de todos los laboratorios no es hacer que funcione un código o ver el resultado de un código, si no el entender cada función que se utiliza y por supuesto aprendernosla, porque al final de cuentas lo mas importante es lo que tenemos en nuestra cabeza y lo que somos capaces de realizar sin ayuda de nada ni de nadie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Referencias\n",
    "\n",
    "Introduction to OpenCV-Python Tutorials¶. (n.d.). Retrieved February 11, 2019, from https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_setup/py_intro/py_intro.html#intro\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Yo declaro, que he realizado este Laboratorio 1 con integridad académica_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
