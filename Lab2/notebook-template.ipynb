{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratorio 2: Getting started with OpenCV for image and video processing\n",
    "\n",
    "Elaborado por: Andrés Hernández Gutiérrez   \n",
    "Matrícula: 23245  \n",
    "Carrera: xxxxxx  \n",
    "Fecha: xxxx-xx-xx (año-mes-día)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-76d20fbf190f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-76d20fbf190f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    En esta sección, el estudiante escribirá una breve introducción a la práctica. El estudiante podría proporcionar una breve descripción de la libraría OpenCV, enlace con Python, y como ambos serán usados para procesamiento de imágenes, captura y post-procesamiento de video.\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#### Introducción\n",
    "En esta sección, el estudiante escribirá una breve introducción a la práctica. El estudiante podría proporcionar una breve descripción de la libraría OpenCV, enlace con Python, y como ambos serán usados para procesamiento de imágenes, captura y post-procesamiento de video.\n",
    "\n",
    "Quienes ya cuenten con la camara RaspiCam, podrán realizar la práctica con ésta para la captura de video, caso contrario, pueden omitir esta parte en el reporte. \n",
    "\n",
    "- item 1\n",
    "- item 2\n",
    "- item 3\n",
    "\n",
    "This an *example*, _example_, **example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objetivos \n",
    "En esta sección, el estudiante enlistará el/los objetivo(s) de la práctica. Pueden apoyarse de los objetivos listados en la práctica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedimiento\n",
    "En las siguientes celdas de código y texto, el estudiante mostrará el procedimiento realizado en la práctica, mostrando imágenes de salida, o enlace a videos capturados con la camara. \n",
    "\n",
    "La siguiente linea muestra un ejemplo para incluir enlaces externos:\n",
    "\n",
    "[Ver imagen de udem](https://www.google.com/search?q=udem&num=20&client=ubuntu&hs=lvY&channel=fs&source=lnms&tbm=isch&sa=X&ved=0ahUKEwjK6Nymn6HgAhVFL6wKHfsFAtsQ_AUIDigB&biw=1920&bih=959#imgrc=s2Qnk7dbzmnsxM:)\n",
    "\n",
    "Para incluir imágenes locales, lo podrá hacer de la siguiente manera:\n",
    "\n",
    "<img src=\"vehicular-traffic.jpg\" width=\"800\" alt=\"Combined Image\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación de librerías\n",
    "Las siguientes celdas de código implementan la lectura, visualización y escritura de imagen en disco. Primero, se importan las librerías que serán utilizadas en el desarrollo de la práctica. La primera de ellas es la librería ```numpy``` utilizada para creación y manipulación de listas, análisis numérico, etc. La segunda librería es ```cv2```, ésta hace uso de la librería OpenCV, la cual implementa una gran variedad de algorítmos de procesamiento de imágenes y visión computaciónal. En nuestra práctica, ```cv2``` nos permitirá leer, procesar, visualizar y escribir imágenes en archivo....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa librerías estandar\n",
    "import numpy as np\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows have been closed properly - bye!\n"
     ]
    }
   ],
   "source": [
    "# read in input image\n",
    "img_in = cv2.imread('../figs/vehicular-traffic.jpg', cv2.IMREAD_COLOR) # alternatively, you can use cv2.IMREAD_GRAYSCALE\n",
    "\n",
    "# create a new window for image visualisation purposes\n",
    "cv2.namedWindow(\"input image\", cv2.WINDOW_AUTOSIZE)  # alternatively, you can use cv2.WINDOW_NORMAL\n",
    "\n",
    "# visualise input image\n",
    "cv2.imshow(\"input image\", img_in)\n",
    "\n",
    "# convert input image from colour to greyscale\n",
    "img_out = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# visualise greyscale image\n",
    "cv2.imshow(\"greyscale image\", img_out)\n",
    "\n",
    "# wait for the user to press a key\n",
    "key = cv2.waitKey(0)\n",
    "\n",
    "# if user presses 's', the grayscale image is write to an image file\n",
    "if key == ord(\"s\"):\n",
    "    \n",
    "    cv2.imwrite('../figs/vehicular-traffic-greyscale.png', img_out)\n",
    "    print('output image has been saved in ../figs/vehicular-traffic-greyscale.png')\n",
    "\n",
    "# destroy windows to free memory  \n",
    "cv2.destroyAllWindows()\n",
    "print('windows have been closed properly - bye!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows have been closed properly\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "def options():\n",
    "    # parse command line arguments\n",
    "    parser = argparse.ArgumentParser('Read, visualise and write image into disk')\n",
    "    parser.add_argument('-i', '--in_image_name', help='input image name', required=True)\n",
    "    parser.add_argument('-o', '--out_image_name', help='output image name', required=True)\n",
    "    args = vars(parser.parse_args())\n",
    "    \n",
    "    return args\n",
    "\n",
    "def processing_image(img_in_name, img_out_name):\n",
    "    \n",
    "     # read in image from file\n",
    "    img_in = cv2.imread(img_in_name, cv2.IMREAD_COLOR) # alternatively, you can use cv2.IMREAD_GRAYSCALE\n",
    "\n",
    "    # verify that image exists\n",
    "    if img_in is None:\n",
    "        print('ERROR: image ', img_in_name, 'could not be read')\n",
    "        exit()\n",
    "\n",
    "    # convert input image from colour to grayscale\n",
    "    img_out = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # create a new window for image purposes\n",
    "    cv2.namedWindow(\"input image\", cv2.WINDOW_AUTOSIZE)  # alternatively, you can use cv2.WINDOW_NORMAL\n",
    "    cv2.namedWindow(\"output image\", cv2.WINDOW_AUTOSIZE) # that option will allow you for window resizing\n",
    "\n",
    "    # visualise input and output image\n",
    "    cv2.imshow(\"input image\", img_in)\n",
    "    cv2.imshow(\"output image\", img_out)\n",
    "\n",
    "    # wait for the user to press a key\n",
    "    key = cv2.waitKey(0)\n",
    "\n",
    "    # if user pressed 's', the grayscale image is write to disk\n",
    "    if key == ord(\"s\"):\n",
    "        cv2.imwrite(img_out_name, img_out)\n",
    "        print('output image has been saved in ../figs/vehicular-traffic-greyscale.png')\n",
    "\n",
    "    # destroy windows to free memory  \n",
    "    cv2.destroyAllWindows()\n",
    "    print('windows have been closed properly')\n",
    "\n",
    "    \n",
    "# main function\n",
    "def main():    \n",
    "    \n",
    "    # uncomment these lines when running on jupyter notebook\n",
    "    # and comment when running as a script on linux terminal\n",
    "    args = {\n",
    "            \"in_image_name\": \"../figs/vehicular-traffic.jpg\",\n",
    "            \"out_image_name\": \"../figs/vehicular-traffic-greyscale.png\"\n",
    "            }\n",
    "    \n",
    "    # comment the following line when running on jupyter notebook\n",
    "    # and uncomment when running as a script on linux terminarl\n",
    "    #args = options()\n",
    "    \n",
    "    in_image_name = args['in_image_name']\n",
    "    out_image_name = args['out_image_name']\n",
    "    \n",
    "    # call processing image\n",
    "    processing_image(in_image_name, out_image_name)\n",
    "    \n",
    "    \n",
    "# run first\n",
    "if __name__=='__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture video from camera - Basic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "# create a VideoCapture object\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# main loop\n",
    "while(True):\n",
    "\n",
    "    # capture new frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # convert from colour to grayscale image\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # visualise image\n",
    "    cv.imshow('frame', frame)\n",
    "\n",
    "    # wait for the user to press 'q' to close the window\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release VideoCapture object\n",
    "cap.release()\n",
    "\n",
    "# destroy windows to free memory\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture video from camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Video specifications:\n",
      "\tframe width:  640.0\n",
      "\tframe height:  480.0\n",
      "\tframe rate:  30.0\n",
      "\tbrightness:  0.5\n",
      "\tcontrast:  0.5\n",
      "\tsaturation:  0.5\n",
      "\thue:  0.0\n",
      "\texposure:  inf\n",
      "\n",
      "capturing video ...\n",
      "closing camera ...\n",
      "camera closed\n",
      "program finished - bye!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def configure_videoCapture(device_index):\n",
    "\n",
    "    \"\"\"\n",
    "    Configure video capture object to handle video device.\n",
    "\n",
    "    Parameters\n",
    "        device_index: int value indicating the index number to access camera\n",
    "\n",
    "    Returns\n",
    "        cap: videoCapture-type object\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # create a videoCapture object and returns either a True or False\n",
    "    cap = cv2.VideoCapture(device_index)\n",
    "\n",
    "    # if camera could not be opened, it displays an error and exits\n",
    "    if not cap.isOpened():\n",
    "        print(\"ERROR: Camera could not be opened\")\n",
    "        exit()\n",
    "\n",
    "    # return videoCapture object 'cap'\n",
    "    return cap\n",
    "\n",
    "\n",
    "def print_video_frame_specs(cap):\n",
    "\n",
    "    \"\"\"\n",
    "    Print video specifications such as video frame width and height, fps,\n",
    "    brightness, contrast, saturation, gain, and exposure.\n",
    "\n",
    "    Parameters\n",
    "        cap: video capture object\n",
    "\n",
    "    Returns\n",
    "        None: this definition only prints information on the command line\n",
    "              window.\n",
    "    \"\"\"    \n",
    "\n",
    "    # retrieve video properties\n",
    "    ret, frame = cap.read()\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # verify that frame was properly captured\n",
    "    if ret == False:\n",
    "        print(\"ERROR: current frame could not be read\")\n",
    "        exit()\n",
    "\n",
    "    else: # if so, video frame stats are displayed\n",
    "\n",
    "        # print video frames specifications\n",
    "        print('\\nVideo specifications:')\n",
    "        print('\\tframe width: ', cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        print('\\tframe height: ', cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        print('\\tframe rate: ', cap.get(cv2.CAP_PROP_FPS))\n",
    "        print('\\tbrightness: ', cap.get(cv2.CAP_PROP_BRIGHTNESS))\n",
    "        print('\\tcontrast: ', cap.get(cv2.CAP_PROP_CONTRAST))\n",
    "        print('\\tsaturation: ', cap.get(cv2.CAP_PROP_SATURATION))\n",
    "        print('\\thue: ', cap.get(cv2.CAP_PROP_GAIN))\n",
    "        print('\\texposure: ', cap.get(cv2.CAP_PROP_EXPOSURE))\n",
    "\n",
    "    # return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def capture_and_process_video(cap):\n",
    "\n",
    "    \"\"\"\n",
    "    Capture live video from a camera connected to your computer. Each frame is\n",
    "    flipped and visualised together with the original frame on separate windows.\n",
    "\n",
    "    Parameters\n",
    "        cap: video capture object\n",
    "\n",
    "    Returns\n",
    "        None: none\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # create a new window for image purposes\n",
    "    cv2.namedWindow(\"input image\", cv2.WINDOW_AUTOSIZE)  # alternatively, you can use cv2.WINDOW_NORMAL\n",
    "    cv2.namedWindow(\"output image\", cv2.WINDOW_AUTOSIZE) # that option will allow you for window resizing\n",
    "\n",
    "\n",
    "    # main loop\n",
    "    print('\\ncapturing video ...')\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "        # capture frame by frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "\t    # verify that frame was properly captured\n",
    "        if ret == False:\n",
    "            print(\"ERROR: current frame could not be read\")\n",
    "            break\n",
    "\n",
    "        # if frame was properly captured, it is converted\n",
    "        # from a colour to a grayscale image\n",
    "        frame_out = cv2.flip(frame,0)\n",
    "\n",
    "        # visualise current frame and grayscale frame\n",
    "        cv2.imshow(\"input image\", frame)\n",
    "        cv2.imshow(\"output image\", frame_out)\n",
    "\n",
    "\n",
    "        # wait for the user to press a key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # return none\n",
    "    return None\n",
    "\n",
    "\n",
    "def free_memory(cap):\n",
    "\n",
    "    \"\"\"\n",
    "    Free memory by releasing videoCapture 'cap' and by destroying/closing all\n",
    "    open windows.\n",
    "\n",
    "    Parameters\n",
    "        cap: video capture object\n",
    "\n",
    "    Returns\n",
    "        None: none\n",
    "    \"\"\"\n",
    "\n",
    "    # when finished, release the VideoCapture object and close windows to free memory\n",
    "    print('closing camera ...')\n",
    "    cap.release()\n",
    "    print('camera closed')\n",
    "    cv2.destroyAllWindows()\n",
    "    print('program finished - bye!\\n')\n",
    "\n",
    "    # return none\n",
    "    return None\n",
    "\n",
    "\n",
    "def run_pipeline(device_index=0):\n",
    "    \"\"\"\n",
    "    Run pipeline to capture, process and visualise both the original frame and\n",
    "    processed frame.\n",
    "\n",
    "    Parameters\n",
    "        device_index: device index - 0 default\n",
    "\n",
    "    Returns\n",
    "        arg: None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # pipeline\n",
    "    cap = configure_videoCapture(device_index)\n",
    "    print_video_frame_specs(cap)\n",
    "    capture_and_process_video(cap)\n",
    "    free_memory(cap)\n",
    "\n",
    "    # return none\n",
    "    return None\n",
    "\n",
    "\n",
    "# run pipeline    \n",
    "run_pipeline(device_index = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Play video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# create a VideoCapture object and specify video file to be read\n",
    "cap = cv2.VideoCapture('../datasets/videos/highway_right_solid_white_line_short.mp4')\n",
    "\n",
    "# main loop\n",
    "while(cap.isOpened()):\n",
    "\n",
    "    # read current frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # validate that frame was capture correctly\n",
    "    if ret:\n",
    "        \n",
    "        # convert frame from colour to gray scale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # show current frame\n",
    "        cv2.imshow('frame',gray)\n",
    "\n",
    "    # wait for the user to press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release VideoCapture object\n",
    "cap.release()\n",
    "\n",
    "# destroy windows to free memory\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones\n",
    "En esta sección, el estudiante incluirá sus conclusiones ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
