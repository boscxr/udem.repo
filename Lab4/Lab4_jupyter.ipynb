{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratorio 4: Image colour space for object segmentation\n",
    "\n",
    "Elaborado por: Oscar Omar Martínez Lujano \n",
    "\n",
    "Matrícula: 352228  \n",
    "Carrera: ITR  \n",
    "Fecha: 2019-02-17  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Thus far, we have seen how to convert a BGR-colour image into a grayscale image using the OpenCV method cv2.cvtColour(frame, cv2.COLOR_BGR2GRAY). This converted a 3-channel image into a single-channel greyscale image. Similarly to the greyscale colour space, there exists a vast number of other colour spaces being the RBG (Red, Blue, Green), HSV (Hue, Saturation, Value), HLS (Hue, Lightness, Saturation), and the LAB (Lightness, Green-to-Magenta, Blue-to-Yellow) colour spaces amongst the most widely used. \n",
    "\n",
    "Depending on the computer vision application being developed, and assuming your vision system captures colour images, you may prefer to process the input images using either the RGB colour space or the Grey colour space. For instance, if you are interested in detecting objects with particular geometric shapes such as circles, triangles, lines, etc., working on the RGB colour space may not add any further information, compared with working on the Grey colour space. This is because detecting the edges of an object is not a function of the object colour; on the contrary, this may make the computer vision algorithm computationally slower, as processing three-channel images always takes more time than processing single-channel images.\n",
    "\n",
    "In a different computer vision application, you may be interested in finding the lane lines on a highway. In this case, you may prefer to integrate colour information into your algorithm as you know that lanes are regularly painted in black or white colour. Furthermore, you also know that lane lines are also painted in either white or yellow colour. Therefore, fusing colour information may facilitate the detection and tracking of lane lines on a highway. Another application where you may wish to integrate colour information into your algorithm is when being interested in traffic lights and skin tone detection. For the former application, it is quite likely that the traffic lights will be yellow, green or red in most cases; whereas for the latter application, depending on factors such as geographical location, ethnic group, gender, age, etc., you may be able to develop a computer vision application for skin detection.\n",
    "\n",
    "We now have a brief understanding on what short of computer vision applications may rely on the use of the RBG or the Grey color space for object detection/segmentation. We also noticed that OpenCV has 274 different colour spaces available for image processing; thus, why there exits so many colour spaces?, when would the HLS colour space be preferred in a computer vision application?. Going back to the automated highway lane line detection task, it turns out that aspects such as lighting conditions highly affect the performance of an algorithm working with RGB colour images. In that situation, we may prefer to convert our RGB image into a different colour space, such as the HSL (hue, saturation, lightness). This has proven to be more robust even when different lighting conditions are present. The figures below show an example of a lane lines segmentation when using the RGB and the HLS colour spaces, respectively. As can be seen, we may consider using the R and G channels to automatically extract the yellow line from the colour image; however, as indicated by the red circle, these two channels are affected by the shadow produced by the high tree located ahead of the road. This may limit the algorithm to detect and track lane lines at short distances. On the contrary, the second image shows how this line could be better detected using either low intensity values from the H channel or high intensity values from the S channel, as these two channels seem to be robust to shadows or to different lighting conditions. Being able to detect the road lane lines at a farther distance makes the vehicle able to respond to an event of emergency accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "In this lab, we will learn about image colour space, particularly about the HSV (Hue, Saturation, Value) and HLS (Hue, Saturation, Lightness) colour maps. You will use this colour space to segment an object in a video sequence, this object can be either a fish swimming in a fishbolw, lane lines on a road, or any other object that can be segmented by using its corresponding HSV components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laboratory Requirements\n",
    "The software, hardware and programming tools required for this lab are listed below:\n",
    "\n",
    "    - Laptop or Raspberry Pi with WiFi connection capabilities\n",
    "    - Jupyter Notebook\n",
    "    - Python >= 3.5.2\n",
    "    - OpenCV 3.2\n",
    "    - Git\n",
    "    - GitHub account\n",
    "    - Markdown editor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure\n",
    "\n",
    "In this code, you will use the OpenCV method hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) to convert the current frame from RGB to HSV. Once you have the hsv image, you will use the method mask = cv2.inRange(hsv, lower_blue, upper_blue) to create a mask image. This will be a binary image with high pixel intensity values in those regions where the colour of interest appears in the current frame. In order to generate a new image that contains the segmented blue colour objects, it is necessary to perform an AND bit-wise operation between the current frame and the mask image, so that only those pixels with high intensity values in the mask image are visualised in the new image.\n",
    "\n",
    "The next images were used to take out hsv_min and hsv_max with GIMP help:\n",
    "\n",
    "<img src=\"Figs/mardigra.png\" width=\"400\" alt=\"Combined Image\" />\n",
    "<img src=\"Figs/volti-01.png\" width=\"400\" alt=\"Combined Image\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Importación de librerías\n",
    "\n",
    "The following libraries are used in the codes of this lab.\n",
    "\n",
    "\n",
    "- ```cv2```: Implementa una gran variedad de algorítmos de procesamiento de imágenes y visión computacional.\n",
    "- ```numpy:``` Crea y manipula listas, análisis numérico, etc.\n",
    "- `matplotlib.pyplot:` Produce publicaciones con figuras de calidad en una variedad de formatos de copia impresa y entornos interactivos en todas las plataformas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa librerías estandar\n",
    "import numpy as numpy\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Object segmentation using the HSV (Hue, Saturation, Value) colour information\n",
    "\n",
    "The code below shows you how to segment (detect) the following objects:\n",
    "\n",
    "    - A fish swimming in a fishbowl\n",
    "    - White lane lines on a running track\n",
    "    - Red lane on a running track\n",
    "    - Hawaiian flowers - blue objects\n",
    "\n",
    "    \n",
    "- `cv2.bitwise_and(src1, src2[, dst[, mask]])`\n",
    "    - Calculates the per-element bit-wise conjunction of two arrays or an array and a scalar.\n",
    "    - src1 – first input array or a scalar..\n",
    "    - src2 – second input array or a scalar.\n",
    "    - src – single input array..\n",
    "    - value – scalar value.\n",
    "    - **returns** - array that has the same size and type as the input arrays.\n",
    "    \n",
    "- `cv.inRange(src, lowerb, upperb[, dst])`\n",
    "    - Checks if array elements lie between the elements of two other arrays. \n",
    "    - src - first input array.\n",
    "    - lowerb - inclusive lower boundary array or a scalar. \n",
    "    - upperb - inclusive upper boundary array or a scalar. \n",
    "    - **returns**: \toutput array of the same size as src and CV_8U type. \n",
    "\n",
    "\n",
    "\n",
    "Información obtenida de:\n",
    "- https://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html#bitwise-and\n",
    "- https://docs.opencv.org/3.4/d2/de8/group__core__array.html#ga48af0ab51e36436c5d04340e036ce981\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    object-segmentation-using-hsv-colour-space.py\n",
    "\n",
    "    add a description of your code here\n",
    "\n",
    "    author: add your fullname\n",
    "    date created: add this info\n",
    "    universidad de monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "# config video object\n",
    "def config_video_source(source_video_file):\n",
    "\n",
    "    # initialise a video capture object\n",
    "    cap = cv2.VideoCapture(source_video_file)\n",
    "\n",
    "    # check that the videocapture object was successfully created\n",
    "    if(not cap.isOpened()):\n",
    "        print(\"Error opening video source\")\n",
    "        exit()\n",
    "\n",
    "    # return videocapture object\n",
    "    return cap\n",
    "\n",
    "\n",
    "# process video\n",
    "def process_video(cap, hsv_min=(20, 20, 29), hsv_max=(40, 200, 200)):\n",
    "\n",
    "\n",
    "    # create new windows for visualisation purposes\n",
    "    cv2.namedWindow('input video', cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow('segmented object', cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # main loop\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "        # grab current frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # verify that frame was properly captured\n",
    "        if ret == False:\n",
    "            print(\"ERROR: current frame could not be read\")            \n",
    "            break\n",
    "\n",
    "        # convert BGR to HSV\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # threshold the hsv image so that only blue pixels are kept\n",
    "        mask = cv2.inRange(hsv, hsv_min, hsv_max)\n",
    "\n",
    "        # AND-bitwise operation between the mask and input images\n",
    "        segmented_objects = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "        # visualise current frame\n",
    "        cv2.imshow('input video',frame)\n",
    "\n",
    "        # visualise segmented blue object\n",
    "        cv2.imshow('segmented object', segmented_objects)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.imwrite('volti-swimming.png', frame)\n",
    "            cv2.imwrite('volti-swimming-segmented.png', segmented_objects)\n",
    "            break\n",
    "\n",
    "\n",
    "# free memory and close open windows\n",
    "def free_memory_amd_close_windows(cap):\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# run pipeline\n",
    "def run_pipeline(dataset_number=1):\n",
    "\n",
    "\n",
    "    # select video sequence\n",
    "    if(dataset_number==1):\n",
    "        # segment volti\n",
    "        cap = config_video_source(source_video_file=\"volti-01.mp4\")\n",
    "        process_video(cap, hsv_min=(115, 30, 0), hsv_max=(190, 250, 250))           \n",
    "\n",
    "    elif(dataset_number==2):\n",
    "        # segment white lane lines\n",
    "        cap = config_video_source(source_video_file=\"running-track.mp4\")\n",
    "        process_video(cap, hsv_min=(130, 0, 100), hsv_max=(160, 255, 255))\n",
    "\n",
    "    elif(dataset_number==3):\n",
    "        # segment red road\n",
    "        cap = config_video_source(source_video_file=\"running-track.mp4\")\n",
    "        process_video(cap, hsv_min=(160, 85, 85), hsv_max=(180, 200, 200))\n",
    "\n",
    "    elif(dataset_number==4):\n",
    "        # segment blue objects\n",
    "        cap = config_video_source(source_video_file=\"mardigrass.mp4\")\n",
    "        process_video(cap, hsv_min=(95, 40, 100), hsv_max=(110, 255, 255))\n",
    "    else:\n",
    "        # enter a valid option\n",
    "        print(\"Please, enter a valid option mate! [1-4]\")\n",
    "        exit()\n",
    "\n",
    "    # free memory and close windows\n",
    "    free_memory_amd_close_windows(cap)\n",
    "\n",
    "\n",
    "# main function\n",
    "def main():    \n",
    "    run_pipeline(dataset_number = 4)\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO COMPLETE THIS SECTION... \n",
    "\n",
    "\n",
    "    - Use the mardigrass.mp4 video sequence to segment multiple objects. In particular, your code should be able to detect and display the segmentation of blue, red, yellow and violet colour objects.\n",
    "    - Use the volti-01.mp4 sequence to segment both the fish (red-ish) and the fishbowl floor (blue-ish).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    object-segmentation-using-hsv-colour-space.py\n",
    "\n",
    "    add a description of your code here\n",
    "\n",
    "    author: add your fullname\n",
    "    date created: add this info\n",
    "    universidad de monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "# config video object\n",
    "def config_video_source(source_video_file):\n",
    "\n",
    "    # initialise a video capture object\n",
    "    cap = cv2.VideoCapture(source_video_file)\n",
    "\n",
    "    # check that the videocapture object was successfully created\n",
    "    if(not cap.isOpened()):\n",
    "        print(\"Error opening video source\")\n",
    "        exit()\n",
    "\n",
    "    # return videocapture object\n",
    "    return cap\n",
    "\n",
    "\n",
    "# process video\n",
    "def process_video(cap, hsv_min=(20, 20, 29), hsv_max=(40, 200, 200)):\n",
    "\n",
    "\n",
    "    # create new windows for visualisation purposes\n",
    "    cv2.namedWindow('input video', cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow('segmented object', cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # main loop\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "        # grab current frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # verify that frame was properly captured\n",
    "        if ret == False:\n",
    "            print(\"ERROR: current frame could not be read\")            \n",
    "            break\n",
    "\n",
    "        # convert BGR to HSV\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # threshold the hsv image so that only blue pixels are kept\n",
    "        mask = cv2.inRange(hsv, hsv_min, hsv_max)\n",
    "\n",
    "        # AND-bitwise operation between the mask and input images\n",
    "        segmented_objects = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "        # visualise current frame\n",
    "        cv2.imshow('input video',frame)\n",
    "\n",
    "        # visualise segmented blue object\n",
    "        cv2.imshow('segmented object', segmented_objects)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.imwrite('volti-swimming.png', frame)\n",
    "            cv2.imwrite('volti-swimming-segmented.png', segmented_objects)\n",
    "            break\n",
    "\n",
    "\n",
    "# free memory and close open windows\n",
    "def free_memory_amd_close_windows(cap):\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# run pipeline\n",
    "def run_pipeline(dataset_number=1):\n",
    "\n",
    "\n",
    "    # select video sequence\n",
    "    if(dataset_number==1):\n",
    "        # blue\n",
    "        cap = config_video_source(source_video_file=\"mardigrass.mp4\")\n",
    "        process_video(cap, hsv_min=(95, 40, 100), hsv_max=(110, 255, 255))\n",
    "        # red \n",
    "        cap = config_video_source(source_video_file=\"mardigrass.mp4\")\n",
    "        process_video(cap, hsv_min=(160, 65, 85), hsv_max=(180, 200, 200))\n",
    "        # yellow \n",
    "        cap = config_video_source(source_video_file=\"mardigrass.mp4\")\n",
    "        process_video(cap, hsv_min=(17, 40, 100), hsv_max=(32, 255, 255))\n",
    "        # violet\n",
    "        cap = config_video_source(source_video_file=\"mardigrass.mp4\")\n",
    "        process_video(cap, hsv_min=(125, 40, 100), hsv_max=(140, 255, 255))\n",
    "                                                           \n",
    "    elif(dataset_number==2):\n",
    "        # blue ish\n",
    "        cap = config_video_source(source_video_file=\"volti-01.mp4\")\n",
    "        process_video(cap, hsv_min=(115, 30, 0), hsv_max=(190, 250, 250))\n",
    "        #red ish \n",
    "        cap = config_video_source(source_video_file=\"volti-01.mp4\")\n",
    "        process_video(cap, hsv_min=(93, 30, 0), hsv_max=(108, 250, 250))\n",
    "        \n",
    "\n",
    "    else:\n",
    "        # enter a valid option\n",
    "        print(\"Please, enter a valid option mate! [1-4]\")\n",
    "        exit()\n",
    "\n",
    "    # free memory and close windows\n",
    "    free_memory_amd_close_windows(cap)\n",
    "\n",
    "\n",
    "# main function\n",
    "def main():    \n",
    "    run_pipeline(dataset_number = 2)\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Yo declaro, que he realizado este Laboratorio 3 con integridad académica_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
